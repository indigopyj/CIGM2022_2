<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Assignment2</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="4f26ae2a-bc96-4465-9fc2-159a8c2d6f71" class="page sans"><header><h1 class="page-title">Assignment2</h1></header><div class="page-body"><p id="e70bbba8-894c-42df-9d57-e876beba3157" class=""><strong>written by 20214396, Yeojeong Park</strong></p><h2 id="d41a7b0b-c6bd-4c44-a86a-ef2326058f27" class="">0. How to run the file</h2><p id="a593a0eb-9fb0-49f8-a112-7a846e2d39b3" class="">First, run the jupyter notebook and open</p><pre id="5dc2e8b6-add3-4618-91fa-f29824d84870" class="code"><code>jupyter notebook</code></pre><p id="f4ed0fc8-d1eb-4c13-9086-18e525c35429" class="">This will print some information about the notebook server in your terminal, including the URL of the web application (by default, <a href="http://localhost:8888/">http://localhost:8888</a>)</p><p id="4460f625-dfbf-4551-a043-d3b84afa3344" class="">Second, if you run the web application, click the file named<strong> ‘Assignment1.ipynb’. </strong></p><p id="67aec3bd-624e-49f0-b886-2401f2beb838" class="">Then, click the [Cell]-[Run All] from the menu bar.</p><figure id="c2ba7c56-bb2c-41b5-ad81-083740165967" class="image"><a href="imgs/Assignment1/run_cells.png"><img style="width:459px" src="imgs/Assignment1/run_cells.png"/></a></figure><p id="bd9ff92a-d036-4ed3-ae59-e836ef5f2bd1" class="">
</p><p id="a4cf4d87-0a94-4215-994e-1eaf171d70c6" class="">
</p><h2 id="f6bafe25-ac1a-4bdd-abf2-c7639476e113" class="">1. Report</h2><h3 id="cdb0e805-fdd3-4057-b189-22776f9d2ed7" class="">INITIALS AND COLOR TRANSFORMATION (5 PTS)</h3><p id="e453f94b-001b-4e89-b58d-0224b45c5a40" class="">
</p><figure id="3bcf4046-5527-4b2a-9ab7-8c0b4f702533" class="image"><a href="imgs/Assignment2/initial.png"><img style="width:407px" src="imgs/Assignment2/initial.png"/></a></figure><p id="e7186956-0365-467b-90ce-6209a343f853" class="">I used ‘scikit-video’ python library to read all frames within each video at once. Therefore, “<strong>frame_face</strong>” and “<strong>frame_baby2</strong>” have tensors whose shapes are [# frames, Height, Width, Channel].  I converted the image into a double-type array by ‘<span style="border-bottom:0.05em solid">.astype(’double’)</span>’, and converted frames to the YIQ color space by ‘<span style="border-bottom:0.05em solid">rgb2yiq</span>’.  As a result, ‘<span style="border-bottom:0.05em solid">YIQframe_face</span>’ and ‘<span style="border-bottom:0.05em solid">YIQframe_baby2</span>’ are video tensors in YIQ color space.</p><p id="906fd12f-3270-4317-a36b-afc7f69bfe83" class="">A ‘face.mp4’ has 301 frames with 592 * 528 size, and a ‘baby2.mp4’ has 900 frames with 352 * 640 size.</p><p id="c674442d-a513-46c7-8c96-73231d352d90" class="">
</p><h3 id="7837d20a-24c4-49d7-9e13-6500f2b714a1" class="">LAPLACIAN PYRAMID (20PTS)</h3><figure id="290d9ebe-9ecc-4b46-aaa9-66f94e41b612" class="image"><a href="imgs/Assignment2/laplacian.png"><img style="width:667px" src="imgs/Assignment2/laplacian.png"/></a></figure><p id="366aef07-e428-48f8-ab1a-4965a4302949" class="">To build a laplacian pyramid, I must construct a gaussian pyramid first. </p><p id="769a32a8-ce42-4a6d-8ff0-7824cc7b93e7" class=""><strong>Gaussian pyramid</strong></p><p id="5e0c1ef0-1f3e-4c71-a2d2-2e0061ee6bb3" class="">I constructed pyramids for every frames, so I iteratively loaded all frames to downsample &amp; blur the frames by ‘<span style="border-bottom:0.05em solid">cv2.pyrDown()</span>’. Also, I had to repeat this step 4 times to build a 4-level pyramid. In practice, I set level 0 for an original frame, and the frame height and width are reduced by 2 times at each level(1 ~ 4). Finally, ‘<span style="border-bottom:0.05em solid">G_tensor_list</span>’ has 5-level pyramids(0 level + 4 levels) for all frames. </p><p id="08ffc457-359c-4e61-a9b5-c7f31ad8a158" class=""><strong>Laplacian pyramid</strong></p><p id="5642dfec-09ea-42e3-8d28-8afa4fef15c2" class="">I can build Laplacian pyramids by taking the difference between adjacent levels of a Gaussian pyramid. First, I upsampled the L-level gaussian image which is a variable ‘<span style="border-bottom:0.05em solid">up_img</span>’ in this code, by ‘<span style="border-bottom:0.05em solid">cv2.pyrUp()</span>’. Then, I subtracted it from the (L-1) level gaussian image. Finally, ‘L<span style="border-bottom:0.05em solid">_tensor_list</span>’ had 4-level pyramids for all frames. I stacked the pyramids from L to 1, so I reversed their orders to set 1 to L in order to match all levels with gaussian pyramids. </p><figure id="e2bbf4cb-c785-4ba5-bb96-3c2837745271" class="image"><a href="imgs/Assignment2/laplacian_result.png"><img style="width:507px" src="imgs/Assignment2/laplacian_result.png"/></a></figure><p id="b52d7b63-9373-4bdb-b363-f25b7a84f32e" class="">I can check the spatial size of each level in gaussian pyramids/laplacian pyramids for two videos.</p><p id="056ea40a-5787-41bb-8474-5593860c9bd0" class="">Now ‘<span style="border-bottom:0.05em solid">face_G_tensor</span>’ and ‘<span style="border-bottom:0.05em solid">baby2_G_tensor</span>’ are tensors of the gaussian pyramids. ‘<span style="border-bottom:0.05em solid">face_L_tensor</span>’ and ‘<span style="border-bottom:0.05em solid">baby2_L_tensor</span>’ are tensors of laplacian pyramid.</p><p id="87e3917d-4bce-4a4c-881d-a82a4413cf12" class="">
</p><h3 id="852f6606-8271-4083-9ffd-3dd71d9b49a5" class="">TEMPORAL FILTERING (30PTS)</h3><p id="0d77120b-c218-411b-8c54-97287367dda0" class=""><strong>Temporal filtering</strong></p><figure id="a596be5c-31b6-486f-ad5d-70c297f771dc" class="image"><a href="imgs/Assignment2/temporal_filtering.png"><img style="width:690px" src="imgs/Assignment2/temporal_filtering.png"/></a></figure><p id="310f04c7-c0f4-4e11-bda5-f801c4d85435" class="">For temporal filtering, I converted the time series corresponding to the value of pixels on laplacian pyramids to the frequency domain using Fast Fourier Transform (‘<span style="border-bottom:0.05em solid">numpy.fft</span>’).  I set the sampling frequencies with step (1/fps). Then, I generated an ideal bandpass filter by finding indices of low/high cut-off frequency, ‘<span style="border-bottom:0.05em solid">low_bound</span>’, and ‘<span style="border-bottom:0.05em solid">high_bound</span>’ here. I filtered the frequency that isn’t within low bound/high_bound by setting 0. Finally, I changed the signal back to the time series. </p><p id="c9b3531b-5385-46c9-a7ff-f9e7d989ea2b" class="">A band-pass filter is applied to an individual pixel in 3-channel, by function ‘<span style="border-bottom:0.05em solid">temporal_bandpass_filter</span>’.</p><p id="a9aa0a51-2596-4999-a8b9-912276c9b7ff" class="">
</p><p id="fa05e17c-204e-4ac5-8efe-b96f4f2a4e84" class=""><strong>Filtering &amp; Amplification</strong></p><figure id="c47d78ec-9eb6-460e-bbdb-c725ee915551" class="image"><a href="imgs/Assignment2/face_filtering.png"><img style="width:676px" src="imgs/Assignment2/face_filtering.png"/></a></figure><figure id="11d1d852-8f27-44c7-a746-e12a8f0ab7da" class="image"><a href="imgs/Assignment2/baby_filtering.png"><img style="width:701px" src="imgs/Assignment2/baby_filtering.png"/></a></figure><p id="f0d17f6d-2039-4143-ba8c-52ae741b2b69" class="">I applied a bandpass filter to ‘face.mp4’ with the parameters described in the original paper. However, for ‘baby2.mp4’, I changed the parameters according to the frequency band of Interest extraction, which will be described later. I set <span style="border-bottom:0.05em solid">freq_min = 0.5</span> and<span style="border-bottom:0.05em solid"> freq_max = 2</span>.</p><p id="12884e92-3935-4a4a-a58e-68190ff4cccb" class=""><mark class="highlight-red">Note that I applied a filter only on the last level of the laplacian pyramids for better visualization of the result videos</mark>. If not, the edges of videos are too emphasized and the results become awkward. (This is my bells and whistles and I did it on purpose which is quite different from the original paper!!)</p><p id="075e7123-e5d6-4b70-94cd-67c24d85e88e" class="">Then, I amplified the signal by multiplying alpha, which is set to <strong>100</strong> for ‘face.mp4’ and <strong>30</strong> for ‘baby2.mp4’. </p><p id="58cd17f2-ec37-4c97-b509-d740533cd56d" class="">
</p><p id="7e86ecd0-eb31-4f63-afd7-a41e7e65e5e5" class=""><strong>Visualization</strong></p><figure id="d933dc8a-638d-43e9-84f3-264d6b6d6f58" class="image"><a href="imgs/Assignment2/freq_visualize.png"><img style="width:512px" src="imgs/Assignment2/freq_visualize.png"/></a></figure><p id="2bec36a3-f521-4793-8d11-a652d2125492" class="">To check whether the filtering performed well, I visualized the frequency of one random pixel before/after filtering. I had done the same process as the function ‘<span style="border-bottom:0.05em solid">temporal_filtering</span>’. I described above but except for ‘<span style="border-bottom:0.05em solid">ifft</span>(inverse fourier transform)’. The picture above is the code for visualization of ‘face.mp4’, and the same process is applied to ‘baby2.mp4’.</p><p id="93916f4b-19f4-4c1d-9776-fe568d9ae9ca" class="">For ‘face.mp4’ video, the visualization result is as follows:</p><figure id="c81ce8c5-bb13-4922-8d1d-abb684c362d0" class="image"><a href="imgs/Assignment2/face_vis.png"><img style="width:533px" src="imgs/Assignment2/face_vis.png"/></a></figure><p id="d2e67887-6bf2-4bd3-b4f0-802720beb58f" class="">, where all of the signal except [-1, -0.83] and [0.83, 1] is set to zero.</p><p id="88605e52-a620-4053-a6ad-fa45b66121e6" class="">For ‘baby2.mp4’, the signal is visualized as:</p><figure id="5d0a4f89-7be9-4e70-89b7-eee6bc26a2ee" class="image"><a href="imgs/Assignment2/baby_vis.png"><img style="width:525px" src="imgs/Assignment2/baby_vis.png"/></a></figure><p id="77ade189-dbd3-48d5-9d68-b3fa17feedc4" class="">, where only signal within [0.5, 2] and [-2, -0.5] is survived.</p><p id="b03176dd-83b6-4e91-9b09-cc90159bb905" class="">
</p><h3 id="49710c43-9fd0-48e6-b8b2-2e0417113afa" class="">IMAGE RECONSTRUCTION (20PTS)</h3><figure id="a64e521b-078c-4dfa-b198-75f5f634554e" class="image"><a href="imgs/Assignment2/reconstruction.png"><img style="width:624px" src="imgs/Assignment2/reconstruction.png"/></a></figure><p id="4614db0a-8605-4b42-ae5d-390259de0eb9" class="">The only step left is to collapse the laplacian pyramids into a single image per frame, by ‘<span style="border-bottom:0.05em solid">final_laplacian_reconstruction</span>’. First, upsample the L-level gaussian image. Then, add it to the (L-1)-level laplacian image. Repeat these two steps until getting the original resolution. Now, we can reconstruct the original image. However, the filtered result should be added back to the original signal. So I add ‘<span style="border-bottom:0.05em solid">final_imgs</span>’ to ‘<span style="border-bottom:0.05em solid">origin_imgs_tensor</span>’ as written in the code. </p><p id="d7a57d86-23bd-4ae6-9228-526d0e90b59d" class="">After reconstruction, I converted the images back to RGB space and generate the videos.</p><p id="4e77f98f-c446-4e09-89f2-a5a69fa03527" class="">Note that I excluded the video generation code in this report.</p><p id="7eacc8cb-4d97-4362-b639-4371026fe0c0" class="">
</p><p id="d15be347-0062-4cc8-82de-d8d5db429f74" class="">
</p><h3 id="598c7b2b-cf03-4445-ab2c-7b54523ffd82" class="">EXTRA CREDIT: CAPTURE AND MOTION-MAGNIFY YOUR OWN VIDEO(S) (UP TO 30 POINTS)</h3><p id="694ba1d8-de78-403a-a782-364e7711c0f9" class="">I filmed my wrist pulse with my smartphone ‘Galaxy S 21’ to magnify the motion and its color.</p><p id="0a618012-0def-4e03-870f-a9241e8c2f77" class="">I did the same process as ‘face.mp4’ and ‘baby2.mp4’. To capture the frequency for magnifying, it was extracted by the step described below.</p><p id="f22150a0-c0ef-442b-9a37-e2e270f58770" class="">
</p><h3 id="49e9bd0f-bfaa-4953-9289-cd916033bb95" class="">EXTRACTING THE FREQUENCY BAND OF INTEREST (30PTS)</h3><figure id="b957f1aa-0e26-4f3a-b1d2-235e002100fa" class="image"><a href="imgs/Assignment2/Untitled%201.png"><img style="width:541px" src="imgs/Assignment2/Untitled%201.png"/></a></figure><p id="9c754e25-5143-48a6-b589-cbb9bf73c642" class="">First of all, I summed the values of all the pixels to analyze the histogram of each frame within the given video. I also converted it to the frequency domain by ‘<span style="border-bottom:0.05em solid">numpy.fft</span>’. The picture is the result of the frequency of the histogram.</p><figure id="adc6fbe1-17a4-4a2e-8052-e10c8088a34c" class="image"><a href="imgs/Assignment2/Untitled%202.png"><img style="width:506px" src="imgs/Assignment2/Untitled%202.png"/></a></figure><p id="d905ae82-a8cf-4881-9dfc-ce62f5d0a26f" class="">I marked only the signal in red which has a large amplitude, and I approximated the low cut-off and high cut-off as 0.0833 and 0.833. </p><figure id="b71d9df8-6ce9-4d38-b6fa-d6397071990c" class="image"><a href="imgs/Assignment2/extract_baby2.png"><img style="width:497px" src="imgs/Assignment2/extract_baby2.png"/></a></figure><p id="cf160d97-afe9-4996-8dfe-2ac67b762237" class="">I also found the low bound/high bound of ‘baby2.mp4’ by implementing the same process and set them as 0.5 and 2.0 individually.</p><p id="d41d4d07-084d-4d1e-a054-d589973cbcb0" class="">
</p><figure id="de97cf3f-64c7-4a37-ad29-ed5915edf83e" class="image"><a href="imgs/Assignment2/custom.png"><img style="width:667px" src="imgs/Assignment2/custom.png"/></a></figure><p id="7af34674-5423-4bb0-8631-28ce175adbdb" class="">Finally, I amplified the signal by multiplying alpha, which is set to <strong>20</strong> empirically.</p><p id="397bc358-dd21-4ba3-85c8-17b54986c8c0" class="">I also implement the image reconstruction and video generation as mentioned above.</p><p id="5c645daf-18fb-4746-a629-eb29d5d6beb3" class="">
</p><h3 id="94cce249-afaf-412f-89ce-c206e48d89f5" class="">ETC</h3><p id="17927c05-e0a7-4a2d-8273-9911f67e8e9f" class="">I attached the input videos and the result videos in the same folder. Please check the final result by watching them!</p><p id="fd3bbd4c-2ffe-4893-9d5f-fb50914acf99" class="">
</p></div></article></body></html>
